{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names =  ['wf_make','wf_address','wf_all','wf_3d','wf_our','wf_over','wf_remove','wf_internet','wf_order','wf_mail',\n",
    "              'wf_receive','wf_will','wf_people','wf_report','wf_addresses','wf_free','wf_business','wf_email','wf_you',\n",
    "              'wf_credit','wf_your','wf_font','wf_000','wf_money','wf_hp','wf_hpl','wf_george','wf_650','wf_lab','wf_labs',\n",
    "             'wf_telnet','wf_857','wf_data','wf_415','wf_85','wf_technology','wf_1999','wf_parts','wf_pm','wf_direct',\n",
    "              'wf_cs','wf_meeting','wf_original','wf_project','wf_re','wf_edu','wf_table','wf_conference','wf_;','wf_(',\n",
    "             'wf_[','wf_!','wf_$','wf_#','wf','crl_average','crl_longest','crl_total']\n",
    "data = pd.read_csv(\"spambase.data.txt\", header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wf_make</th>\n",
       "      <th>wf_address</th>\n",
       "      <th>wf_all</th>\n",
       "      <th>wf_3d</th>\n",
       "      <th>wf_our</th>\n",
       "      <th>wf_over</th>\n",
       "      <th>wf_remove</th>\n",
       "      <th>wf_internet</th>\n",
       "      <th>wf_order</th>\n",
       "      <th>wf_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>wf_;</th>\n",
       "      <th>wf_(</th>\n",
       "      <th>wf_[</th>\n",
       "      <th>wf_!</th>\n",
       "      <th>wf_$</th>\n",
       "      <th>wf_#</th>\n",
       "      <th>wf</th>\n",
       "      <th>crl_average</th>\n",
       "      <th>crl_longest</th>\n",
       "      <th>crl_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "      <td>4601.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104553</td>\n",
       "      <td>0.213015</td>\n",
       "      <td>0.280656</td>\n",
       "      <td>0.065425</td>\n",
       "      <td>0.312223</td>\n",
       "      <td>0.095901</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.105295</td>\n",
       "      <td>0.090067</td>\n",
       "      <td>0.239413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038575</td>\n",
       "      <td>0.139030</td>\n",
       "      <td>0.016976</td>\n",
       "      <td>0.269071</td>\n",
       "      <td>0.075811</td>\n",
       "      <td>0.044238</td>\n",
       "      <td>5.191515</td>\n",
       "      <td>52.172789</td>\n",
       "      <td>283.289285</td>\n",
       "      <td>0.394045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305358</td>\n",
       "      <td>1.290575</td>\n",
       "      <td>0.504143</td>\n",
       "      <td>1.395151</td>\n",
       "      <td>0.672513</td>\n",
       "      <td>0.273824</td>\n",
       "      <td>0.391441</td>\n",
       "      <td>0.401071</td>\n",
       "      <td>0.278616</td>\n",
       "      <td>0.644755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243471</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.109394</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>0.245882</td>\n",
       "      <td>0.429342</td>\n",
       "      <td>31.729449</td>\n",
       "      <td>194.891310</td>\n",
       "      <td>606.347851</td>\n",
       "      <td>0.488698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.276000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.706000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           wf_make   wf_address       wf_all        wf_3d       wf_our  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.104553     0.213015     0.280656     0.065425     0.312223   \n",
       "std       0.305358     1.290575     0.504143     1.395151     0.672513   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.420000     0.000000     0.380000   \n",
       "max       4.540000    14.280000     5.100000    42.810000    10.000000   \n",
       "\n",
       "           wf_over    wf_remove  wf_internet     wf_order      wf_mail  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      0.095901     0.114208     0.105295     0.090067     0.239413   \n",
       "std       0.273824     0.391441     0.401071     0.278616     0.644755   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.160000   \n",
       "max       5.880000     7.270000    11.110000     5.260000    18.180000   \n",
       "\n",
       "          ...              wf_;         wf_(         wf_[         wf_!  \\\n",
       "count     ...       4601.000000  4601.000000  4601.000000  4601.000000   \n",
       "mean      ...          0.038575     0.139030     0.016976     0.269071   \n",
       "std       ...          0.243471     0.270355     0.109394     0.815672   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.000000     0.065000     0.000000     0.000000   \n",
       "75%       ...          0.000000     0.188000     0.000000     0.315000   \n",
       "max       ...          4.385000     9.752000     4.081000    32.478000   \n",
       "\n",
       "              wf_$         wf_#           wf  crl_average   crl_longest  \\\n",
       "count  4601.000000  4601.000000  4601.000000  4601.000000   4601.000000   \n",
       "mean      0.075811     0.044238     5.191515    52.172789    283.289285   \n",
       "std       0.245882     0.429342    31.729449   194.891310    606.347851   \n",
       "min       0.000000     0.000000     1.000000     1.000000      1.000000   \n",
       "25%       0.000000     0.000000     1.588000     6.000000     35.000000   \n",
       "50%       0.000000     0.000000     2.276000    15.000000     95.000000   \n",
       "75%       0.052000     0.000000     3.706000    43.000000    266.000000   \n",
       "max       6.003000    19.829000  1102.500000  9989.000000  15841.000000   \n",
       "\n",
       "         crl_total  \n",
       "count  4601.000000  \n",
       "mean      0.394045  \n",
       "std       0.488698  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       1.000000  \n",
       "max       1.000000  \n",
       "\n",
       "[8 rows x 58 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, classification_report,accuracy_score, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_func(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cost = cm[0][1] * 10 + cm[1][0] * 1\n",
    "    return cost\n",
    "\n",
    "scoring1 = make_scorer(loss_func, greater_is_better= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score = {'decision_tree':{},'knn':{},'logistic':{},'NB':{},'svm':{}, 'bagging':{}, 'adaboost':{}, \\\n",
    "             'random_forest':{}, 'gradient_boosting':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NB': {},\n",
       " 'adaboost': {},\n",
       " 'bagging': {},\n",
       " 'decision_tree': {},\n",
       " 'gradient_boosting': {},\n",
       " 'knn': {},\n",
       " 'logistic': {},\n",
       " 'random_forest': {},\n",
       " 'svm': {}}"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_para = {'penalty':['l1','l2'], 'C':[100,10,1,0.1,0.01,0.001]}\n",
    "\n",
    "log = LogisticRegression()\n",
    "grid_log = GridSearchCV(log, log_para, cv=5, scoring = scoring1)\n",
    "grid_log.fit(X_train, y_train)\n",
    "y_pred_log = grid_log.predict(X_test)\n",
    "nested_score_log = cross_val_score(grid_log, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['logistic']['mean'] = np.mean(nested_score_log)\n",
    "cost_score['logistic']['std'] = np.std(nested_score_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.95      0.93       686\n",
      "          1       0.92      0.88      0.90       465\n",
      "\n",
      "avg / total       0.92      0.92      0.92      1151\n",
      "\n",
      "\n",
      "The cost for the model is 416\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_log))\n",
    "cm = confusion_matrix(y_test, y_pred_log)\n",
    "cost_log = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['logistic']['cost'] = cost_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['logistic']['accuracy'] = accuracy_score(y_test, y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_log.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_par =  {'criterion':['entropy'],'max_depth':list(range(8,11)),'min_samples_leaf':list(range(1,4)),'random_state':[45]}\n",
    "d_tree = DecisionTreeClassifier()\n",
    "grid_tree = GridSearchCV(d_tree, tree_par, cv = 5, scoring = scoring1)\n",
    "grid_tree.fit(X_train, y_train)\n",
    "y_pred_tree = grid_tree.predict(X_test)\n",
    "nested_score_tree = cross_val_score(grid_tree, X, y, cv =5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from costcla.models import CostSensitiveDecisionTreeClassifier\n",
    "from costcla.metrics import cost_loss\n",
    "model = CostSensitiveDecisionTreeClassifier()\n",
    "cost_matrix_train = np.array(len(X_train)*[10,1,0,0]).reshape(len(X_train),4)\n",
    "cost_matrix_test = np.array(len(X_test)*[10,1,0,0]).reshape(len(X_test),4)\n",
    "model.fit(X_train, y_train, cost_matrix_train)\n",
    "y_pred = model.predict(X_test)\n",
    "loss = cost_loss(y_test, y_pred, cost_matrix_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['decision_tree']['mean'] = np.mean(nested_score_tree)\n",
    "cost_score['decision_tree']['std'] = np.std(nested_score_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.95      0.94       686\n",
      "          1       0.92      0.90      0.91       465\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1151\n",
      "\n",
      "\n",
      "The cost for the model is 408\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_tree))\n",
    "cm = confusion_matrix(y_test, y_pred_tree)\n",
    "cost_tree = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['decision_tree']['cost'] = cost_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['decision_tree']['accuracy'] = accuracy_score(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'random_state': 45}"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_tree.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_par = {'n_neighbors':list(range(3,21)),'weights':['uniform','distance']}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, knn_par, cv = 5, scoring = scoring1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "y_pred_knn = grid_knn.predict(X_test)\n",
    "nested_score_knn = cross_val_score(grid_knn, X, y, cv =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['knn']['mean'] = np.mean(nested_score_knn)\n",
    "cost_score['knn']['std'] = np.std(nested_score_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.95      0.92       686\n",
      "          1       0.91      0.82      0.87       465\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1151\n",
      "\n",
      "\n",
      "The cost for the model is 443\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_knn))\n",
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "cost_knn = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['knn']['cost'] = cost_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['knn']['accuracy'] = accuracy_score(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 4, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "nested_score_nb = cross_val_score(nb, X = X, y = y, cv = 5, scoring = scoring1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['NB']['mean'] = np.mean(nested_score_nb)\n",
    "cost_score['NB']['std'] = np.std(nested_score_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.72      0.82       686\n",
      "          1       0.70      0.95      0.80       465\n",
      "\n",
      "avg / total       0.85      0.81      0.81      1151\n",
      "\n",
      "\n",
      "The cost for the model is 1935\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nb))\n",
    "cm = confusion_matrix(y_test, y_pred_nb)\n",
    "cost_nb = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['NB']['cost'] = cost_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['NB']['accuracy'] = accuracy_score(y_test, y_pred_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Hyper parameter\n",
    "para_svm = [{'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5], 'C': [1, 10, 100, 1000]}]\n",
    "svm = SVC(kernel = 'rbf')\n",
    "grid_svm = GridSearchCV(svm, para_svm, cv = 5, scoring = scoring1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "nested_score_svm = cross_val_score(grid_svm, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save running time\n",
    "para_svm = {'kernel':['rbf'],'C':[1],'gamma':[0.5]} \n",
    "svm = SVC(random_state = 45,probability = True)\n",
    "grid_svm = GridSearchCV(svm, para_svm, cv = 5, scoring= scoring1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "y_pred_svm = grid_svm.predict(X_test)\n",
    "nested_score_svm = cross_val_score(grid_svm, X = X, y = y, cv = 5) \n",
    "cost_score['svm']['mean'] = np.mean(nested_score_svm)\n",
    "cost_score['svm']['std'] = np.std(nested_score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['svm']['mean'] = np.mean(nested_score_svm)\n",
    "cost_score['svm']['std'] = np.std(nested_score_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.5}"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.99      0.86       686\n",
      "          1       0.98      0.53      0.69       465\n",
      "\n",
      "avg / total       0.85      0.81      0.79      1151\n",
      "\n",
      "\n",
      "The cost for the model is 258\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_svm))\n",
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "cost_svm = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['svm']['cost'] = cost_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['svm']['accuracy'] = accuracy_score(y_test, y_pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_bag = {'base_estimator':[DecisionTreeClassifier(), KNeighborsClassifier()],\n",
    "            \"max_samples\": [0.5, 1.0]}\n",
    "bag = BaggingClassifier()\n",
    "grid_bag = GridSearchCV(bag, para_bag, cv = 5, scoring = scoring1)\n",
    "grid_bag.fit(X_train, y_train)\n",
    "y_pred_bag = grid_bag.predict(X_test)\n",
    "nested_score_bag = cross_val_score(grid_bag, X, y, cv =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save running time (Use the best hyper parameter)\n",
    "para_bag = {'base_estimator': [DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "             max_features=None, max_leaf_nodes=None,\n",
    "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "             min_samples_leaf=1, min_samples_split=2,\n",
    "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "             splitter='best')], 'max_samples': [1.0]}\n",
    "bag = BaggingClassifier(random_state = 45)\n",
    "grid_bag = GridSearchCV(bag, para_bag, cv = 5, scoring = scoring1)\n",
    "grid_bag.fit(X_train, y_train)\n",
    "y_pred_bag = grid_bag.predict(X_test)\n",
    "nested_score_bag = cross_val_score(grid_bag, X, y, cv =5)\n",
    "cost_score['bagging']['mean'] = np.mean(nested_score_bag)\n",
    "cost_score['bagging']['std'] = np.std(nested_score_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['bagging']['mean'] = np.mean(nested_score_bag)\n",
    "cost_score['bagging']['std'] = np.std(nested_score_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'), 'max_samples': 1.0}"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_bag.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       686\n",
      "          1       0.96      0.90      0.93       465\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1151\n",
      "\n",
      "\n",
      "The cost for the model is 206\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_bag))\n",
    "cm = confusion_matrix(y_test, y_pred_bag)\n",
    "cost_bag = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['bagging']['cost'] = cost_bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['bagging']['accuracy'] = accuracy_score(y_test, y_pred_bag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboosting Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "para_ada = {'n_estimators':[100,200,300,400,500,600], 'base_estimator':[DecisionTreeClassifier(max_depth=i) for i in range(1,9)]}\n",
    "ada = AdaBoostClassifier()\n",
    "random_ada = RandomizedSearchCV(ada, para_ada, cv=3, scoring = scoring1)\n",
    "random_ada.fit(X_train, y_train)\n",
    "y_pred_ada = random_ada.predict(X_test)\n",
    "nested_score_ada = cross_val_score(random_ada, X, y, cv =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save running time\n",
    "para_ada = {'base_estimator': [DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n",
    "             max_features=None, max_leaf_nodes=None,\n",
    "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "             min_samples_leaf=1, min_samples_split=2,\n",
    "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
    "             splitter='best')], 'n_estimators': [400]}\n",
    "ada = AdaBoostClassifier()\n",
    "random_ada = GridSearchCV(ada, para_ada, cv=3, scoring = scoring1)\n",
    "random_ada.fit(X_train, y_train)\n",
    "y_pred_ada = random_ada.predict(X_test)\n",
    "nested_score_ada = cross_val_score(random_ada, X, y, cv =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['adaboost']['mean'] = np.mean(nested_score_ada)\n",
    "cost_score['adaboost']['std'] = np.std(nested_score_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base_estimator': DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=7,\n",
       "             max_features=None, max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "             splitter='best'), 'n_estimators': 400}"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.97      0.96       686\n",
      "          1       0.95      0.94      0.94       465\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1151\n",
      "\n",
      "\n",
      "The cost for the model is 260\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_ada))\n",
    "cm = confusion_matrix(y_test, y_pred_ada)\n",
    "cost_ada = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_ada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['adaboost']['cost'] = cost_ada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['adaboost']['accuracy'] = accuracy_score(y_test, y_pred_ada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "random_grid = {'max_depth': max_depth, 'min_samples_split': min_samples_split,'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rd_rf = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, cv = 5, random_state=42, scoring = scoring1)\n",
    "rd_rf.fit(X_train, y_train)\n",
    "y_pred_rf = rd_rf.predict(X_test)\n",
    "nested_score_rf = cross_val_score(rd_rf, X, y, cv =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['random_forest']['mean'] = np.mean(nested_score_rf)\n",
    "cost_score['random_forest']['std'] = np.std(nested_score_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 2}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.98      0.96       686\n",
      "          1       0.97      0.91      0.94       465\n",
      "\n",
      "avg / total       0.95      0.95      0.95      1151\n",
      "\n",
      "\n",
      "The cost for the model is 171\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_rf))\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "cost_rf = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['random_forest']['cost'] = cost_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['random_forest']['accuracy'] = accuracy_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25, random_state=123)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_para = {'max_depth':range(5,16,2), 'min_samples_split':range(200,1001,200)}\n",
    "gbr = GradientBoostingClassifier()\n",
    "rd_gbr = RandomizedSearchCV(gbr, gbr_para, cv = 3, random_state=42, scoring = scoring1)\n",
    "rd_gbr.fit(X_train, y_train)\n",
    "y_pred_gbr = rd_gbr.predict(X_test)\n",
    "nested_score_gbr = cross_val_score(rd_gbr, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save running time\n",
    "gbr_para = {'max_depth':[5], 'min_samples_split':[200]}\n",
    "gbr = GradientBoostingClassifier()\n",
    "rd_gbr = GridSearchCV(gbr, gbr_para, cv = 3, scoring = scoring1)\n",
    "rd_gbr.fit(X_train, y_train)\n",
    "y_pred_gbr = rd_gbr.predict(X_test)\n",
    "nested_score_gbr = cross_val_score(rd_gbr, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_score['gradient_boosting']['mean'] = np.mean(nested_score_gbr)\n",
    "cost_score['gradient_boosting']['std'] = np.std(nested_score_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5, 'min_samples_split': 200}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd_gbr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97       686\n",
      "          1       0.96      0.94      0.95       465\n",
      "\n",
      "avg / total       0.96      0.96      0.96      1151\n",
      "\n",
      "\n",
      "The cost for the model is 188\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_gbr))\n",
    "cm = confusion_matrix(y_test, y_pred_gbr)\n",
    "cost_gbr = cm[0][1]*10 + cm[1][0]*1\n",
    "print()\n",
    "print('The cost for the model is %d' %cost_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list['gradient_boosting']['cost'] = cost_gbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "accu['gradient_boosting']['accuracy'] = accuracy_score(y_test, y_pred_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost-Sensitive Model Comparison\n",
      "\n",
      "                     mean         std\n",
      "svm                -316.6   53.894712\n",
      "gradient_boosting  -363.2  384.353171\n",
      "random_forest      -371.6  380.423764\n",
      "adaboost           -391.6  333.841040\n",
      "bagging            -414.4  375.257565\n",
      "logistic           -429.2  282.542315\n",
      "decision_tree      -490.6  451.960441\n",
      "knn                -880.0  257.469221\n",
      "NB                -1456.4  496.220354\n"
     ]
    }
   ],
   "source": [
    "a = pd.DataFrame(cost_score)\n",
    "a = a.T\n",
    "\n",
    "print('Cost-Sensitive Model Comparison')\n",
    "print()\n",
    "print(a.sort_values(by=['mean'], ascending = False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
